\subsection{User Control Experience}
The focus in this project is to make a controller that is based on the user’s gestures and movements. In order to accomplish that kind of controller a lot of research is required on how the movements has to be executed in order to make it a smooth and positive experience for the user. If our project wants to achieve that feeling it needs research about how the human body communicates by the use of body language. As body language is a huge subject the group has chosen to only focus on the essentials of the subject and the body parts that we find relevant for our webcam to detect. This decision was made since we only need some parts of this subject and if we should fully understand this subject there should be spend more time than the group can provide for this semester.

In order to create gestures for our webcam to detect there has to be an understanding of what a gesture is. Many have asked this question and according to Adam Kendon an experiment were made with this goal in mind in the year 1978 \parencite{Kendon2004}:
\bigskip

\emph{"What are the features that an action must have for it to be treated as a gesture?"} \parencite{Kendon2004}
\bigskip

This experiment was performed by having twenty people with no psychology or behavioral science background. This background check was made to be sure that it wouldn’t have any impact on the test. The people was placed in rooms and told to watch a four minute movie clip without sound made for the experiment. After the movie was done each person was asked to describe what movements they had seen the man in the movie make. The aim was to find out what movements the subjects picked out in their descriptions and to find out what different sorts of movements they identified. After more tests and a lot research the scientists came to a conclusion.
\bigskip

\emph{“Gesture is a label for actions that have the features of manifest deliberate expressiveness. They are those actions or those aspects of another’s actions that, having these features, tend to be directly perceived as being under the guidance of the observed person’s voluntary control and being done for the purposes of expression rather than in the service of some practical aim.”} \parencite{Kendon2004}
\bigskip

As recording to the research, gestures have a huge impact on the listeners. Even though webcams don’t have any ears these theories can still be of use for us. As Susan Goldin-Meadow writes in her book \parencite{Meadow2005} people still use gestures even though they are not communicating with another person. This could be you at home practicing a speech or simple just talking to yourself. You talk but even if you are the only one in the room you would still perform your gestures as you were trying to explain something to another person.

Now that we know what a gesture is the research can continue on which gestures we want to implement in our program. A few common gestures have been found that are being used in our daily lives that could be useable for the webcam to detect \parencite{Businessballs}. For the more uncommon gestures the group has to do some testing in order to figure out what would suit the majority of our testers.
\bigskip

Common gestures:

Hands:
\begin{itemize}
\item Thumb up - positive approval, agreement, all well
\item Thumb down - disapproval, failure
\item Index finger and thumb touching at tips - satisfaction
\end{itemize}

Head:
\begin{itemize}
\item Head nodding - agreement
\item Head shaking - disagreement
\end{itemize}
\bigskip

A last thing to mention is that people got a personal space also called Proxemics with five different comfort zones. Close intimate, Intimate, Personal, Social-consultative and Public. All of these zones define how comfortable the person is with another person’s standing around them. So this is something that the group should keep in mind when creating our controller. If the aim will be for the Social-consultative and Public zone it is then important according to Edward Twitchell Hall that we place cameras and other players at least 1.2 meters away from the player in order for the person to feel comfortable between themselves and others \parencite{Businessballs}.

So what can be concluded from our research is that in order for us to make a good controller that is based on the user’s gestures and movements. A test has to be made in order to show how people want to handle the different movements and actions that our webcam will observe. With the information received from the initial tests it is then possible to create a pattern that fits the majority of our volunteers that was used for initial testing. After that it is then possible to implement the right movements and gestures for our controller and then give the right instructions for our movements at the final test.  This process should make it a smooth and positive experience to use the controller created for the project.
