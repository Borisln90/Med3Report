\subsection{User Control Experience}
The focus in this project is to make a controller that is based on the user’s gestures and movements. In order to accomplish that kind of controller a lot of research is required on how the movements has to be executed in order to make it a smooth and positive experience for the user. If this project wants to achieve that feeling it needs research about how the human body communicates by the use of body language. As body language is a huge subject, it has been chosen to only focus on the essentials of the subject and the relevant body parts for the webcam to detect.

In order to create gestures for the webcam to detect there has to be an understanding of what a gesture is. Many have asked this question and according to Adam Kendon an experiment were made with this goal in mind in the year 1978 \parencite{Kendon2004}:
\bigskip

\emph{"What are the features that an action must have for it to be treated as a gesture?"} \parencite{Kendon2004}
\bigskip

This experiment was performed by having twenty people with no psychology or behavioral science background. This background check was made to be sure that it would not have any impact on the test. The people was placed in rooms and told to watch a four minute movie clip without sound made for the experiment. After the movie was done each person was asked to describe what movements they had seen the man in the movie make. The aim was to find out what movements the subjects picked out in their descriptions and to find out what different sorts of movements they identified. After more tests and a lot research the scientists came to a conclusion.
\bigskip

\emph{“Gesture is a label for actions that have the features of manifest deliberate expressiveness. They are those actions or those aspects of another’s actions that, having these features, tend to be directly perceived as being under the guidance of the observed person’s voluntary control and being done for the purposes of expression rather than in the service of some practical aim.”} \parencite{Kendon2004}
\bigskip

As recording to the research, gestures have a huge impact on the listeners. Even though webcams do not have any ears these theories can still be of use for us. As Susan Goldin-Meadow writes in her book \parencite{Meadow2005} people still use gestures even though they are not communicating with another person. This could be you at home practicing a speech or simple just talking to yourself. You talk but even if you are the only one in the room you would still perform your gestures, as you were trying to explain something to another person.

Now that it is known what a gesture is, the research can continue on which gestures needs to be implemented. A few common gestures have been found that are being used in the daily lives that could be useable for the webcam to detect \parencite{Businessballs}.
\bigskip

Common gestures:

Hands:
\begin{itemize}
\item Thumb up - positive approval, agreement, all well
\item Thumb down - disapproval, failure
\item Index finger and thumb touching at tips - satisfaction
\end{itemize}

Head:
\begin{itemize}
\item Head nodding - agreement
\item Head shaking - disagreement
\end{itemize}
\bigskip

A last thing of mention is that people has a personal space also called Proxemics with five different comfort zones. close intimate, intimate, personal, social-consultative and public. All of these zones define how comfortable the person is with another person standing around them. So this is something that should be kept in mind when creating the controller. If the aim will be for the Social-consultative and Public zone. It is then important according to Edward Twitchell Hall that we place cameras and other players at least 1.2 meters away from the player in order for the person to feel comfortable between themselves and others \parencite{Businessballs}.

So what can be concluded from this research is that in order to make a good controller that is based on the user’s gestures and movements. A test has to be made in order to show how people want to handle the different movements and actions that the webcam will observe. With the information received from the initial tests it is then possible to create a pattern that fits the majority of volunteers used for initial testing. After that it should be possible to implement the right movements and gestures for the controller and then give the right instructions for our movements at the final test.  This process should make it a smooth and positive experience to use the controller created for the project.
